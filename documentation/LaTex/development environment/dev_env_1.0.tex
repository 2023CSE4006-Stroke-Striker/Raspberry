\section{\textbf{Development Environment}}

% \subsection{Choice of software development platform}
\subsection{\textbf{OS}}
% 우리는 리눅스의 일종인 우분투를 기본 OS로 설정했다. 이 우분투는 학습된 AI 모델이 웹 서버를 통해 배포될 때 필요한 가상 머신의 OS이다. CLI 기반으로 가볍고 빠르며 프로그래머 입장에서 친숙한 운영체제이기 때문에 우분투를 선택했다.
We set Ubuntu, a type of Linux, as the default OS. This Ubuntu is the OS of the virtual machine required when the learned AI model is deployed through a web server. I chose Ubuntu because it is a CLI-based, lightweight, fast, and familiar operating system for programmers.\\
\subsection{\textbf{Raspberry Pi}}
%우리의 목적은 가전기기에 인공지능을 탑재해 스마트 IoT를 만드는 것이다. 따라서 진정한 IoT의 구현을 위해 Raspberry pi를 사용할 것이다. 독립적인 컴퓨터를 사용하여 가전을 통제한다는 점에서 진정한 IoT기술을 구현하고자 하였다. 데스크탑에서 우리가 의도한 프로그램을 만들어낼 수 있겠지만, 데스크탑과 가전에 들어가는 보드의 성능차이가 굉장히 많이 나기에 이것이 IoT를 위한 프로그램이라고 할 수 없다고 생각하였다. 실제로 우리의 예상대로 데스크탑에서 돌아갔던 프로그램이 라즈베리파이에서는 돌아가지 않음을 발견하였다. 대표적인 이유로 사용하는 bit나 linux version 등의 OS의 차이, default library의 차이, 카메라를 인식하는 매커니즘의 차이, CPU, GPU 등 하드웨어적 성능 차이, 발열 문제, 성능 최적화 등이 있었다. 데스크탑에서 프로그래밍을 할 때에는 잘 고려하지 않았던 부분들을 Raspberry pi를 사용함으로써 깨달을 수 있었고 이를 통해 진정한 가전을 위한 프로그램을 만들 수 있었다. Raspberry pi에서의 프로그래밍을 위해 SSH를 이용하였다. Mac OS에서 SSH를 통해 Raspberry pi에 접근하였고 코드를 썼다.SSH를 이용한 이유는 편리함 때문이다. Raspberry pi에서 직접 코딩을 하게 되면 Editor를 따로 설치해야하고 편리한 코딩을 위한 Library도 따로 설치해야한다. 또한 키보드 입력에 대한 반응속도도 빠르지 못하여 편리하지 않다. 그래서 같은 Wi-fi에 접속한 후 지정된 IP를 통해 ssh 서버를 사용하였다.%
Our goal is to integrate artificial intelligence into home appliances to create a smart IoT system. To achieve true IoT implementation, we have chosen to use Raspberry Pi. We aim to implement genuine IoT technology by controlling home appliances with an independent computer. While we can develop the intended program on a desktop, we believe it's not suitable for IoT because of the significant differences in performance between a desktop and the board used in home appliances.\\

In practice, we found that a program that worked well on a desktop did not run smoothly on a Raspberry Pi due to several factors. These factors include differences in the operating system, such as bit and Linux version, variations in default libraries, differences in the camera recognition mechanism, variations in hardware performance, such as CPU and GPU, heat-related issues, and performance optimization. By using Raspberry Pi, we have come to realize aspects that were not carefully considered during desktop programming, allowing us to create a program truly suited for home appliances.\\

To program on Raspberry Pi, we utilized SSH. We accessed the Raspberry Pi via SSH from Mac OS and wrote the code. The reason for using SSH was convenience. Programming directly on Raspberry Pi would require installing a separate editor and libraries for efficient coding. Additionally, the response time for keyboard input is not very fast, making it less convenient. Therefore, we connected to the same Wi-Fi network and used the SSH server via the designated IP address.\\

\subsection{\textbf{Languages}}
\subsubsection{\textbf{Python}}

\begin{figure}[htp]
\centering
\includegraphics[width=3cm]{images/python.png}
\caption{Python}
\label{fig:python}
\end{figure}
    
% AI model을 설계할 때 사용한 언어이고 프로그래밍 할 때 주로 사용된 언어이다. Python으로 AI model을 만든 이유는 다음과 같다. 첫째, 다양한 라이브러리. 각종 AI model을 설계할 때 유용한 라이브러리를 python을 통해 편하게 사용할 수 있다. 예를 들면, support vector machine과 같은 기계학습 모델을 구현할 때 사용 가능한 scikit-learn, 각종 수치계산을 도와주는 numpy 등 여러 라이브러리가 준비되어 있다. 둘째, 딥러닝 프레임워크를 쉽게 사용할 수 있다. PyTorch, Keras와 같은 딥러닝을 구현하는데 도움을 주는 프레임워크를 사용하면 각 단계를 모듈화하고 특히 back-propagation을 쉽게 처리할 수 있다. 마지막으로 웹 서버와 통신하는데 필요한 API에서 FastAPI를 함께 사용해 pythonic한 코드를 만들 수 있다. 이와 같은 이유로 Python을 AI model을 구현하는데 주 언어로 사용했다.
It is the language used to design AI models and is mainly used for programming. The reasons for creating an AI model in Python are as follows.
\\

\\
First, various libraries. When designing various AI models, you can conveniently use useful libraries through Python. For example, there are several libraries available, such as scikit-learn that can be used when implementing machine learning models such as support vector machine, and numpy, which helps with various numerical calculations.
\\

\\
Second, deep learning frameworks are easy to use. By using frameworks that help implement deep learning, such as PyTorch or Keras, you can modularize each step and handle back-propagation especially easily. Lastly, you can create pythonic code by using FastAPI in the API required to communicate with the web server. For this reason, Python was used as the main language to implement the AI model.\\




\begin{table}[h]
    \caption{a version of Software/Language/Tool}
    \begin{tabular}{|p{2.6cm}|p{1.7cm}|p{3.4cm}|}
    \hline
    Name & Version \\ \hline
      Raspberry Pi & Raspi 4B 4GB \\ \hline
      Rasbian & Devian BookWorm \\ \hline
      Camera & PiCamera 2\\ \hline
      Ubuntu & 22.04\\ \hline
      Uvicorn & 0.23.2 with CPython 3.10.12 on Linux\\ \hline
      Python & 3.10.12 \\ \hline
      OpenCV & 4.5.5 \\ \hline
      Dlib & 19.23.2 \\ \hline
      NUGU & SKT Jan. 18 Release \\ \hline
      
    \end{tabular}
    \end{table}


\subsection{\textbf{Environment Resources}}
\subsubsection{\textbf{AWS Lightsail}}
\begin{itemize}
    \item OS: Ubuntu 22.04.1 LTS (GNU/Linux 6.2.0-1014-aws x86\_64)
    \item CPU: Intel(R) Xeon(R) Platinum 8259CL CPU @ 2.50GHz
    \item RAM: 1GB RAM
    \item Storage: 40GB SSD
\end{itemize}
\subsubsection{\textbf{Google Colab Pro}}
\begin{itemize}
    \item GPU: T4 GPU
    \item GPU RAM: 15GB
    \item System RAM: 12GB
\end{itemize}

\subsection{\textbf{Estimated Costs}}
\begin{itemize}
    \item AWS Lightsail: \$3.5/month
    \item Colab Pro: \$9.99/month
    \item Raspberry Pi 4B 4GB: \$70\\
\end{itemize}
% Google Colab Pro는 AI model 학습 시에만 사용하므로 정기적인 비용이 부과되지는 않을 것으로 사료된다. 따라서 AWS Lightsail 비용만 생각하면 된다.


\section{\textbf{Software in use}}
\subsection{\textbf{AWS}}
% Amazon Web Service로 서버를 구축하는 등의 작업을 진행했고 아래와 같은 기능을 사용했다. 
We carried out tasks such as building a server with Amazon Web Service and used the functions below. \\
\subsubsection{\textbf{AWS Lightsail}}
% AWS Lightsail로 웹 서버를 동작시킬 수 있는 가상환경을 구축했다. AWS에서 가상환경을 설정하려면 EC2도 사용할 수 있지만 AWS Lightsail을 이용한 이유는 다음과 같다. 첫째, 소규모의 프로젝트이다. EC2보다 간소화된 버전으로 비교적 제약점이 존재하지만 웹 서버로 동작시키기에는 부족함이 없고 오히려 사용하지 않는 기능들이 많은 것보다 안정적이고 단순하다. 둘째, 월정액 과금 시스템이다. EC2는 인스턴스를 사용한만큼 요금이 부과되는 방식이지만 Lightsail은 정해진 요금으로 동작하기 때문에 24시간 켜놓는 서버용 가상머신으로는 Lightsail이 더욱 적합하다고 판단했다. 위와 같은 이유로 AI model을 배포하는데 사용되는 가상머신은 AWS의 Lightsail을 사용했다. 
We built a virtual environment to run a web server using AWS Lightsail. To set up a virtual environment in AWS, you can also use EC2, but the reasons for using AWS Lightsail are as follows.\\
First, it is a small-scale project. It is a simpler version than EC2 and has relatively limitations, but it is sufficient to operate as a web server and is more stable and simple than those with many unused functions.\\
Second, it is a monthly billing system. EC2 charges for the amount of instances used, but Lightsail operates at a fixed rate, so we decided that Lightsail would be more suitable as a server virtual machine that is turned on 24 hours a day. For the above reasons, the virtual machine used to deploy the AI ​​model used AWS's Lightsail.\\

\subsubsection{\textbf{AWS }}

\subsection{\textbf{scp}}
scp stands for "Secure Copy Protocol," and it is a command-line tool used to securely transfer files and directories between a local host and a remote host or between two remote hosts over a network. scp is a part of the SSH (Secure Shell) suite of network protocols and provides a secure way to copy files and data from one location to another.\\
\subsection{\textbf{joblib}}
joblib is a Python library used for serialization, especially for efficiently storing and loading Python objects, often used for handling large Numpy arrays or complex data structures. It is commonly employed in data analysis, machine learning, and scientific research to save and load Python objects or share objects between processes. There are many advantages: \\
First, Efficient Serialization. joblib can serialize Python objects into binary format and store them on disk efficiently. This is particularly useful for handling large data.
\\Second, Numpy Array Support. joblib supports a variety of Python data structures, including Numpy arrays, and it can compress and store them. We use 'joblib' as below usage. Storing trained models and their parameters to reuse them later or for model deployment. \\

\subsection{\textbf{scikit-learn}}
\cite{scikit-learn}
scikit-learn (formerly scikits.learn and also known as sklearn) is a free software machine learning library for the Python programming language. It features various classification, regression and clustering algorithms including support-vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy. Scikit-learn is a NumFOCUS fiscally sponsored project.\\
\subsubsection{\textbf{skimage.io}}
scikit-image (a.k.a. skimage) is a collection of algorithms for image processing and computer vision.
The main package of skimage only provides a few utilities for converting between image data types; for most features, you need to import one of the following subpackages:\\
\subsection{\textbf{PIL}}
\cite{PIL}
Python Imaging Library is a free and open-source additional library for the Python programming language that adds support for opening, manipulating, and saving many different image file formats. It is available for Windows, Mac OS X and Linux. The latest version of PIL is 1.1.7, was released in September 2009 and supports Python 1.5.2–2.7. Development of the original project, known as PIL, was discontinued in 2011.\\
Subsequently, a successor project named Pillow forked the PIL repository and added Python 3.x support This fork has been adopted as a replacement for the original PIL in Linux distributions including Debian[5] and Ubuntu (since 13.04).\\
\subsection{\textbf{NumPy}}
\cite{NumPy}
NumPy is a library for the Python programming language, adding support for large, multi-dimensional arrays and matrices, along with a large collection of high-level mathematical functions to operate on these arrays. The predecessor of NumPy, Numeric, was originally created by Jim Hugunin with contributions from several other developers.\\
 
\\ NumPy is open-source software and has many contributors. NumPy is a NumFOCUS fiscally sponsored project.
NumPy targets the CPython reference implementation of Python, which is a non-optimizing bytecode interpreter. Mathematical algorithms written for this version of Python often run much slower than compiled equivalents due to the absence of compiler optimization. NumPy addresses the slowness problem partly by providing multidimensional arrays and functions and operators that operate efficiently on arrays; using these requires rewriting some code, mostly inner loops, using NumPy.\\

Using NumPy in Python gives functionality comparable to MATLAB since they are both interpreted, and they both allow the user to write fast programs as long as most operations work on arrays or matrices instead of scalars.\\

\\In comparison, MATLAB boasts a large number of additional toolboxes, notably Simulink, whereas NumPy is intrinsically integrated with Python, a more modern and complete programming language. Moreover, complementary Python packages are available; SciPy is a library that adds more MATLAB-like functionality and Matplotlib is a plotting package that provides MATLAB-like plotting functionality. Although matlab can perform sparse matrix operations, numpy alone cannot perform such operations and requires the use of the scipy.sparse library. Internally, both MATLAB and NumPy rely on BLAS and LAPACK for efficient linear algebra computations.\\

\\Python bindings of the widely used computer vision library OpenCV utilize NumPy arrays to store and operate on data. Since images with multiple channels are simply represented as three-dimensional arrays, indexing, slicing or masking with other arrays are very efficient ways to access specific pixels of an image. The NumPy array as universal data structure in OpenCV for images, extracted feature points, filter kernels and many more vastly simplifies the programming workflow and debugging.\\


\subsection{\textbf{Google Colab Pro}}
% Google Colab은 Google에서 제공하는 클라우드 기반의 Jupyter 노트북 환경이다. 이 무료 서비스를 사용하면 웹 브라우저를 통해 Python 코드를 작성하고 실행할 수 있고, 데이터 분석, 머신러닝 모델 개발, 연구 등 다양한 작업에 활용할 수 있다. 이 Google Colab을 활용하면 개인 사용자 컴퓨터의 성능과 용량 제한에 구애받지 않을 수 있고 AI model 학습을 독립적으로 진행할 수 있다. 또한 GPU나 TPU를 원격으로 연결해 사용할 수 있는 환경을 제공하기 때문에 딥러닝 모델 학습고 같은 계산 집약적인 연산에 유용하다. 마지막으로 개인 사용자 컴퓨터에서 Python code를 작성하기 위해서는 가상환경 설치 및 각종 라이브러리를 설치해야 하는 수고가 있다. Google Colab으로 사용자는 이런 수고로움에서 벗어나 온전히 구현에만 집중할 수 있다.
Google Colab is a cloud-based Jupyter notebook environment provided by Google. This free service allows you to write and run Python code through a web browser, and can be used for a variety of tasks, including data analysis, machine learning model development, and research.
\\

\\
By utilizing this Google Colab, you are not restricted by the performance and capacity limitations of individual users' computers and can proceed with AI model learning independently. In addition, it provides an environment where GPU or TPU can be remotely connected and used, so it is useful for computationally intensive operations such as deep learning model training. Lastly, in order to write Python code on a personal user computer, there is the need to install a virtual environment and various libraries. With Google Colab, users can free themselves from this hassle and focus entirely on implementation.\\

\subsection{\textbf{FastAPI}}
% FastAPI는 Python을 사용하여 빠르고 현대적인 웹 애플리케이션 및 API를 빌드하기 위한 웹 프레임워크이다. FastAPI는 사용하기 쉽고 성능이 우수하며, Python 3.6 이상 버전을 지원한다. 웹 서버를 구축할 때 FastAPI를 선택한 이유는 다음과 같다. 첫째, Python Framework. FastAPI는 Python Web Framework로 AI model을 제작할 때 사용한 언어인 Python과 연관이 깊다. 따라서 웹 서버를 제작할 때 일관성을 유지해 버그를 줄일 수 있다. 둘째, 대화형 API 문서를 생성할 수 있다. 대화형 API 문서를 통해 AI model을 만드는 개발자에서도 자체적으로 디버깅을 진행할 수 있어 편하다. 이런 이유로 FastAPI를 선택했다.
FastAPI is a web framework for building fast, modern web applications and APIs using Python. FastAPI is easy to use, has excellent performance, and supports Python 3.6 or higher. The reasons for choosing FastAPI when building a web server are as follows. 
\\

\\
First, the Python Framework. FastAPI is closely related to Python, the language used to create AI models with the Python Web Framework. Therefore, bugs can be reduced by maintaining consistency when creating a web server.
\\

\\
Second, you can create interactive API documentation. It is convenient because developers who create AI models can also carry out debugging on their own through interactive API documents. For this reason, I chose FastAPI.\\
\subsubsection{\textbf{File}}
The File class in FastAPI is used to represent an uploaded file in your application. It's commonly used as a parameter in your route's function to handle file uploads. Here is an example python code:
\begin{verbatim}
from fastapi import FastAPI, File

app = FastAPI()

@app.post("/uploadfile/")
async def upload_file(file: UploadFile):
    # Do something with the uploaded file
    return {"filename": file.filename}
\end{verbatim}
\textbf{Attributes of 'File'}
\begin{itemize}
    \item filename: This attribute contains the name of the uploaded file.
    \item content\_type: The MIME content type of the uploaded file.
    \item file: The actual file data, which can be read or processed.
\end{itemize}
\textbf{Handling the Uploaded file}
You can perform various operations on the uploaded file using the attributes. For example, you can save the file to disk, read its contents, check the content type, or perform any other custom logic.

\subsubsection{\textbf{UploadFile}}
The UploadFile class is a specialized class provided by FastAPI for handling file uploads. It contains additional functionality for managing the uploaded files. Here is an example python code:
\begin{verbatim}
from fastapi import FastAPI, UploadFile

app = FastAPI()

@app.post("/uploadfile/")
async def upload_file(file: UploadFile):
    # Do something with the uploaded file
    return {"filename": file.filename}
\end{verbatim}
\textbf{Attributes of 'UploadFile'}
\begin{itemize}
    \item filename: This attribute contains the name of the uploaded file.
    \item content\_type: The MIME content type of the uploaded file.
    \item file: The actual file data, which can be read or processed.
    \item read(): Allows you to read the content of the uploaded file as bytes.
    \item save(): You can use this method to save the uploaded file to a specified location on your server.
\end{itemize}
\\
\subsection{\textbf{Uvicorn}}
Uvicorn is a popular ASGI (Asynchronous Server Gateway Interface) server that is commonly used to deploy web applications, particularly FastAPI applications, in the Python ecosystem. It's designed for high-performance, asynchronous web serving, and it's often used in conjunction with ASGI frameworks like FastAPI and Starlette.


\subsection{\textbf{Deep learning Framework}}
% AI model을 구현할 때 딥러닝 모델을 만든다면 scikit-learn 라이브러리로는 부족하다. 각종 layer를 모듈화하고 back-propagation을 용이하게 만들어주는 딥러닝 프레임워크가 필요하다. 본 프로젝트에서는 아래와 같은 Pytorch를 사용했다.
When implementing an AI model, if you create a deep learning model, the scikit-learn library is not enough. A deep learning framework that modularizes various layers and facilitates back-propagation is needed. In this project, Pytorch was used as shown below.\\
\subsubsection{\textbf{Pytorch}}
% PyTorch는 딥러닝 및 기계 학습을 위한 오픈 소스 머신러닝 라이브러리로, 주로 Python 언어를 사용하여 모델을 개발하고 학습시키는 데 사용됩니다. PyTorch는 많은 연구원과 기업에서 널리 사용된다. 여러 Deep Learning Framework 중 Pytorch를 이용한 이유는 다음과 같다. 첫째, 동적 계산 그래프. PyTorch의 가장 큰 특징 중 하나는 동적 계산 그래프를 사용하는 것입니다. 이것은 모델을 정의하고 계산할 때 그래프를 구성하는 방식을 의미합니다. 이로써 모델을 동적으로 변경하고 디버깅하기가 훨씬 쉬워집니다. 둘째, GPU를 이용한 AI model 학습. scikit-learn을 이용해 기계학습 모델을 구현했을 때는 CPU만으로 학습을 진행했다. PyTorch는 NVIDIA GPU를 사용하여 모델 학습 및 추론을 가속화할 수 있는 기능을 제공하므로 더 빠른 학습이 가능하다. 셋째, 자동 미분이 가능하다. PyTorch는 자동 미분(automatic differentiation)을 지원하여 그래디언트(gradient)를 쉽게 계산할 수 있습니다. 이는 역전파(backpropagation) 및 경사 하강법(gradient descent)과 같은 학습 알고리즘을 구현할 때 쉽게 구현할 수 있도록 도와준다. 실제로 후술할 Transformer 알고리즘을 구현할 때 위와 같은 강점이 있는 Pytorch로 구현을 진행했다.
PyTorch is an open source machine learning library for deep learning and machine learning, primarily used to develop and train models using the Python language. PyTorch is widely used by many researchers and companies. The reasons for using Pytorch among various Deep Learning Frameworks are as follows.
\\

First, the dynamic computation graph. One of the best features of PyTorch is its use of dynamic computation graphs. This refers to the way the graph is constructed when defining and calculating models. This makes it much easier to dynamically change and debug models.
\\

Second, AI model learning using GPU. When implementing a machine learning model using scikit-learn, learning was performed using only the CPU. PyTorch provides the ability to accelerate model training and inference using NVIDIA GPUs, enabling faster training. 
\\

Third, automatic differentiation is possible. PyTorch supports automatic differentiation, making it easy to calculate gradients. This makes it easier to implement learning algorithms such as back-propagation and gradient descent. In fact, when implementing the Transformer algorithm, which will be described later, it was implemented using Pytorch, which has the above strengths.\\

\subsection{\textbf{Support Vector Machine}}
\cite{SVM}
In machine learning, support vector machines (SVMs, also support vector networks) are supervised learning models with associated learning algorithms that analyze data for classification and regression analysis. 
\\

SVMs are one of the most robust prediction methods, being based on statistical learning frameworks or VC theory proposed by Vapnik (1982, 1995) and Chervonenkis (1974). Given a set of training examples, each marked as belonging to one of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). \\

SVM maps training examples to points in space so as to maximise the width of the gap between the two categories. New examples are then mapped into that same space and predicted to belong to a category based on which side of the gap they fall.
\\

In addition to performing linear classification, SVMs can efficiently perform a non-linear classification using what is called the kernel trick, implicitly mapping their inputs into high-dimensional feature spaces.
\\

The support vector clustering algorithm, created by Hava Siegelmann and Vladimir Vapnik, applies the statistics of support vectors, developed in the support vector machines algorithm, to categorize unlabeled data. These data sets require unsupervised learning approaches, which attempt to find natural clustering of the data to groups and, then, to map new data according to these clusters.\\

\subsubsection{\textbf{Motivation}}
Classifying data is a common task in machine learning.
\\

Suppose some given data points each belong to one of two classes, and the goal is to decide which class a ''new'' data point will be in. In the case of support vector machines, a data point is viewed as a \(p\) - dimensional vector (a list of \(p\) numbers), and we want to know whether we can separate such points with a \((p-1)\)-dimensional hyperplane. This is called a linear classifier. There are many hyperplanes that might classify the data. One reasonable choice as the best hyperplane is the one that represents the largest separation, or margin, between the two classes. So we choose the hyperplane so that the distance from it to the nearest data point on each side is maximized. If such a hyperplane exists, it is known as the 'maximum-margin hyperplane' and the linear classifier it defines is known as a 'margin classifier'; or equivalently, the perceptron of optimal stability.
\\

More formally, a support vector machine constructs a hyperplane or set of hyperplanes in a high or infinite-dimensional space, which can be used for classification, regression, or other tasks like outliers detection. Intuitively, a good separation is achieved by the hyperplane that has the largest distance to the nearest training-data point of any class (so-called functional margin), since in general the larger the margin, the lower the generalization error of the classifier. A lower generalization error means that the implementer is less likely to experience overfitting.
\\

Whereas the original problem may be stated in a finite-dimensional space, it often happens that the sets to discriminate are not linearly separable in that space. For this reason, it was proposed that the original finite-dimensional space be mapped into a much higher-dimensional space, presumably making the separation easier in that space. To keep the computational load reasonable, the mappings used by SVM schemes are designed to ensure that dot products of pairs of input data vectors may be computed easily in terms of the variables in the original space, by defining them in terms of a kernel function \(k(x, y)\) selected to suit the problem. The hyperplanes in the higher-dimensional space are defined as the set of points whose dot product with a vector in that space is constant, where such a set of vectors is an orthogonal (and thus minimal) set of vectors that defines a hyperplane. The vectors defining the hyperplanes can be chosen to be linear combinations with parameters \(\alpha_i\) of images of feature vectors \(x_i\) that occur in the data base. With this choice of a hyperplane, the points \(x\) in the feature space that are mapped into the hyperplane are defined by the relation \(\textstyle\sum_i \alpha_i k(x_i, x) = \textbf{constant}.\)  Note that if  \(k(x, y)\) becomes small as \(y\) grows further away from \(x\), each term in the sum measures the degree of closeness of the test point \(x\) to the corresponding data base point \(x_i\). In this way, the sum of kernels above can be used to measure the relative nearness of each test point to the data points originating in one or the other of the sets to be discriminated. Note the fact that the set of points \(x\) mapped into any hyperplane can be quite convoluted as a result, allowing much more complex discrimination between sets that are not convex at all in the original space.
\\

\subsubsection{\textbf{Linear SVM}}
We are given a training dataset of \(n\) points of the form

\[(\mathbf{x}_1, y_1), \ldots, (\mathbf{x}_n, y_n),\]

where the \(y_i\) are either 1 or −1, each indicating the class to which the point \(\mathbf{x}_i\) belongs. Each \(\mathbf{x}_i\) is a \(p\)-dimensional real vector. We want to find the "maximum-margin hyperplane" that divides the group of points \(\mathbf{x}_i\) for which \(y_i = 1\) from the group of points for which \(y_i = -1\), which is defined so that the distance between the hyperplane and the nearest point \(\mathbf{x}_i\)  from either group is maximized.
\\

Any hyperplane can be written as the set of points \(\mathbf{x}\) satisfying

\[\mathbf{w}^\mathsf{T} \mathbf{x} - b = 0,\]

where \(\mathbf{w}\) is the (not necessarily normalized) normal vector to the hyperplane. This is much like Hesse normal form, except that \(\mathbf{w}\) is not necessarily a unit vector. The parameter \(\tfrac{b}{\|\mathbf{w}\|}\) determines the offset of the hyperplane from the origin along the normal vector \(\mathbf{w}\).
\\

\textbf{Hard-margin} \\
If the training data is linearly separable, we can select two parallel hyperplanes that separate the two classes of data, so that the distance between them is as large as possible. The region bounded by these two hyperplanes is called the "margin", and the maximum-margin hyperplane is the hyperplane that lies halfway between them. With a normalized or standardized dataset, these hyperplanes can be described by the equations 
 \(\mathbf{w}^\mathsf{T} \mathbf{x} - b = 1\) (anything on or above this boundary is of one class, with label 1)
and 
\(\mathbf{w}^\mathsf{T} \mathbf{x} - b = -1\)(anything on or below this boundary is of the other class, with label −1).
\\

Geometrically, the distance between these two hyperplanes is \(\tfrac{2}{\|\mathbf{w}\|}\), so to maximize the distance between the planes we want to minimize \(\|\mathbf{w}\|\). The distance is computed using the distance from a point to a plane equation. We also have to prevent data points from falling into the margin, we add the following constraint: for each \(i\) either

\[\mathbf{w}^\mathsf{T} \mathbf{x}_i - b \ge 1 \, , \text{ if } y_i = 1,\]

or

\[\mathbf{w}^\mathsf{T} \mathbf{x}_i - b \le -1 \, , \text{ if } y_i = -1.\]

These constraints state that each data point must lie on the correct side of the margin.
\\

This can be rewritten as

\begin{equation}
    y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b) \ge 1, \quad \text{ for all } 1 \le i \le n.
\end{equation}

We can put this together to get the optimization problem:

\begin{align}
&\underset{\mathbf{w},\;b}{\operatorname{minimize}} && \|\mathbf{w}\|_2^2\\
&\text{subject to} && y_i(\mathbf{w}^\top \mathbf{x}_i - b) \geq 1 \quad \forall i \in \{1,\dots,n\}
\end{align}

The \(\mathbf{w}\) and \(b\) that solve this problem determine our classifier, \(\mathbf{x} \mapsto\) sgn\((\mathbf{w}^\mathsf{T} \mathbf{x} - b) \) where sgn\((\cdot)\) is the sign function.
\\

An important consequence of this geometric description is that the max-margin hyperplane is completely determined by those  \(\mathbf{x}_i\) that lie nearest to it. These \(\mathbf{x}_i\) are called 'support vectors'.
\\

\textbf{Soft-margin} \\
To extend SVM to cases in which the data are not linearly separable, the 'hinge loss' function is helpful

\[\max\left(0, 1 - y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b)\right).\]

Note that \(y_i\) is the 'i'-th target (i.e., in this case, 1 or −1), and \(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b\) is the ''i''-th output.
\\

This function is zero if the constraint in {(1)} is satisfied, in other words, if $\mathbf{x}_i$ lies on the correct side of the margin. For data on the wrong side of the margin, the function's value is proportional to the distance from the margin.
\\

The goal of the optimization then is to minimize

\[\lambda \lVert \mathbf{w} \rVert^2 +\left[\frac 1 n \sum_{i=1}^n \max\left(0, 1 - y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b)\right) \right],\]

where the parameter $\lambda > 0$ determines the trade-off between increasing the margin size and ensuring that the \(\mathbf{x}_i<\) lie on the correct side of the margin. By deconstructing the hinge loss, this optimization problem can be massaged into the following:

\begin{align}
&\underset{\mathbf{w},\;b,\;\mathbf{\zeta}}{\operatorname{minimize}} &&\|\mathbf{w}\|_2^2 + C\sum_{i=1}^n \zeta_i\\
&\text{subject to} && y_i(\mathbf{w}^\top \mathbf{x}_i - b) \geq 1 - \zeta_i, \quad \zeta_i \geq 0 \quad \forall i\in \{1,\dots,n\}
\end{align}

Thus, for large values of $C$, it will behave similar to the hard-margin SVM, if the input data are linearly classifiable, but will still learn if a classification rule is viable or not. ($\lambda$ is inversely related to $C$, e.g. in 'LIBSVM'.)
\\

\subsubsection{\textbf{Non-linear kernel}}
We use rbf kernel to deal with non-linear problem. These are introduction about kernel method. The algorithm is formally similar, except that every dot product is replaced by a nonlinear kernel function. This allows the algorithm to fit the maximum-margin hyperplane in a transformed feature space. The transformation may be nonlinear and the transformed space high-dimensional; although the classifier is a hyperplane in the transformed feature space, it may be nonlinear in the original input space.
\\

It is noteworthy that working in a higher-dimensional feature space increases the generalization error of support vector machines, although given enough samples the algorithm still performs well.\\

Some common kernels include: \\
* Polynomial (homogeneous):

\[k(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i \cdot \mathbf{x}_j)^d\]
Particularly, when \(d=1\), this becomes the linear kernel. \\

* Polynomial(inhomogeneous):

\[k(\mathbf{x}_i, \mathbf{x}_j) = (\mathbf{x}_i \cdot \mathbf{x}_j + r)^d\]

* Gaussian radial basis function:

\[k(\mathbf{x}_i, \mathbf{x}_j) = \exp\left(-\gamma \left\|\mathbf{x}_i - \mathbf{x}_j\right\|^2\right)\]

for \(\gamma > 0\). Sometimes parametrized using \(\gamma = 1/(2\sigma^2)\). \\

* Sigmoid function (Hyperbolic tangent):

\[k(\mathbf{x_i}, \mathbf{x_j}) = \tanh(\kappa \mathbf{x}_i \cdot \mathbf{x}_j + c)\]
for some (not every) \(\kappa > 0\) and \(c < 0\)
\subsubsection{\textbf{Computing the SVM classifier}}
Computing the (soft-margin) SVM classifier amounts to minimizing an expression of the form
\[\left[\frac 1 n \sum_{i=1}^n \max\left(0, 1 - y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b)\right) \right] + \lambda \|\mathbf{w}\|^2\].
\\

We focus on the soft-margin classifier since, as noted above, choosing a sufficiently small value for \(\lambda\)  yields the hard-margin classifier for linearly classifiable input data. The classical approach, which involves reducing above term to a quadratic programming problem, is detailed below. Then, more recent approaches such as sub-gradient descent and coordinate descent will be discussed. \\
\\
\textbf{Primal} \\
Minimizing above term can be rewritten as a constrained optimization problem with a differentiable objective function in the following way.

For each \(i \in \{1,\,\ldots,\,n\}\) we introduce a variable \(\zeta_i = \max\left(0, 1 - y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b)\right)\). Note that \(\zeta\) is the smallest nonnegative number satisfying \(y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b) \geq 1 - \zeta_i.\)

Thus we can rewrite the optimization problem as follows
\begin{align}
&\text{minimize } \frac 1 n \sum_{i=1}^n \zeta_i + \lambda \|\mathbf{w}\|^2 \\[0.5ex]
&\text{subject to } y_i\left(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b\right) \geq 1 - \zeta_i \, \text{ and } \, \zeta_i \geq 0,\, \text{for all } i.
\end{align}
This is called the ''primal'' problem.
\\

\textbf{Dual} \\
By solving for the Lagrangian dual of the above problem, one obtains the simplified problem
\begin{align}
&\text{maximize}\,\, f(c_1 \ldots c_n) =  \sum_{i=1}^n c_i - \frac 1 2 \sum_{i=1}^n\sum_{j=1}^n y_i c_i(\mathbf{x}_i^\mathsf{T} \mathbf{x}_j)y_j c_j, \\
&\text{subject to } \sum_{i=1}^n c_iy_i = 0,\,\text{and } 0 \leq c_i \leq \frac{1}{2n\lambda}\;\text{for all }i.
\end{align}

This is called the ''dual'' problem. Since the dual maximization problem is a quadratic function of the \(c_i\) subject to linear constraints, it is efficiently solvable by quadratic programming algorithms.

Here, the variables \(c_i\) are defined such that
\[\mathbf{w} = \sum_{i=1}^n c_iy_i \mathbf{x}_i.\]
Moreover, \(c_i = 0\) exactly when \(\mathbf{x}_i\) lies on the correct side of the margin, and \(0 < c_i <(2n\lambda)^{-1}\) when \(\mathbf{x}_i\)lies on the margin's boundary. It follows that \(\mathbf{w}\) can be written as a linear combination of the support vectors.

The offset, \(b\), can be recovered by finding an \(\mathbf{x}_i\) on the margin's boundary and solving

\[y_i(\mathbf{w}^\mathsf{T} \mathbf{x}_i - b) = 1 \iff b = \mathbf{w}^\mathsf{T} \mathbf{x}_i - y_i .\]

(Note that \(y_i^{-1}=y_i\) since \(y_i=\pm 1\).)
\\

\textbf{Kernel Trick} \\
Suppose now that we would like to learn a nonlinear classification rule which corresponds to a linear classification rule for the transformed data points \(\varphi(\mathbf{x}_i).\) Moreover, we are given a kernel function \(k\) which satisfies \(k(\mathbf{x}_i, \mathbf{x}_j) = \varphi(\mathbf{x}_i) \cdot \varphi(\mathbf{x}_j)\).

We know the classification vector \(\mathbf{w}\)in the transformed space satisfies

\[\mathbf{w} = \sum_{i=1}^n c_iy_i\varphi(\mathbf{x}_i),\]

where, the \(c_i\) are obtained by solving the optimization problem

\begin{align}
\text{max}\,\, f(\mathbf{c}) &=  \sum_{i=1}^n c_i - \frac 1 2 \sum_{i=1}^n\sum_{j=1}^n y_ic_i(\varphi(\mathbf{x}_i) \cdot \varphi(\mathbf{x}_j))y_jc_j \\
&=  \sum_{i=1}^n c_i - \frac 1 2 \sum_{i=1}^n\sum_{j=1}^n y_ic_ik(\mathbf{x}_i, \mathbf{x}_j)y_jc_j \\
\text{subject to } \sum_{i=1}^n c_i y_i &= 0,\,\text{and } 0 \leq c_i \leq \frac{1}{2n\lambda}\;\text{for all }i.
\end{align}
The coefficients \(c_i\) can be solved for using quadratic programming, as before. Again, we can find some index \(i\) such that \(0 < c_i <(2n\lambda)^{-1}\), so that \(\varphi(\mathbf{x}_i)\)lies on the boundary of the margin in the transformed space, and then solve

\begin{align}
b = \mathbf{w}^\mathsf{T} \varphi(\mathbf{x}_i) - y_i &= \left[\sum_{j=1}^n c_jy_j\varphi(\mathbf{x}_j) \cdot \varphi(\mathbf{x}_i)\right] - y_i \\
  &= \left[\sum_{j=1}^n c_jy_jk(\mathbf{x}_j, \mathbf{x}_i)\right] - y_i.
\end{align}

Finally,
\[\mathbf{z} \mapsto \sgn(\mathbf{w}^\mathsf{T} \varphi(\mathbf{z}) - b) = \sgn \left(\left[\sum_{i=1}^n c_iy_ik(\mathbf{x}_i, \mathbf{z})\right] - b\right).\]
\\
\subsection{\textbf{Transformer}}
\cite{Transformer}
A transformer is a deep learning architecture, initially proposed in 2017, that relies on the parallel multi-head attention mechanism. It is notable for requiring less training time than previous recurrent neural architectures, such as long short-term memory (LSTM), and its later variation has been prevalently adopted for training large language models on large (language) datasets, such as the Wikipedia corpus and Common Crawl, by virtue of the parallelized processing of input sequence. Input text is split into n-grams encoded as tokens and each token is converted into a vector via looking up from a word embedding table. At each layer, each token is then contextualized within the scope of the context window with other (unmasked) tokens via a parallel multi-head attention mechanism allowing the signal for key tokens to be amplified and less important tokens to be diminished.
\\

This architecture is now used not only in natural language processing and computer vision, but also in audio and multi-modal processing. It has also led to the development of pre-trained systems, such as generative pre-trained transformers (GPTs) and BERT (Bidirectional Encoder Representations from Transformers).
\\
\subsubsection{\textbf{Architecture}}
All transformers have the same primary components:
\\
\begin{itemize}
    \item Tokenizers, which convert text into tokens.\\
    \item A single embedding layer, which convert tokens and positions of the tokens into vector representations.\\
    \item Transformer layers, which carry out repeated transformations on the vector representations, extracting more and more linguistic information. These consist of alternating attention and feedforward layers.\\
    \item (optional) Un-embedding layer, which converts the final vector representations back to a probability distribution over the tokens.\\
\end{itemize}
Transformer layers can be one of two types, ''encoder'' and ''decoder''. In the original paper both of them were used, while later models included only one type of them. BERT is an example of encoder-only model; GPT are decoder-only models.
\\

\textbf{Input}\\
The input text is parsed into tokens by a tokenizer, most often a byte pair encoding tokenizer, and each token is converted into a vector via looking up from a word embedding table. Then, positional information of the token is added to the word embedding.
\\

\textbf{Encoder/decoder architecture} \\
Like earlier seq2seq models, the original transformer model used an '''encoder/decoder''' architecture. The encoder consists of encoding layers that process the input tokens iteratively one layer after another, while the decoder consists of decoding layers that iteratively process the encoder's output as well as the decoder output's tokens so far.
\\

The function of each encoder layer is to generate contextualized token representations, where each representation corresponds to a token that "mixes" information from other input tokens via self-attention mechanism. Each decoder layer contains two attention sublayers: 
\\
(1) cross-attention for incorporating the output of encoder (contextualized input token representations), and (2) self-attention for "mixing" information among the input tokens to the decoder (i.e., the tokens generated so far during inference time).
\\

Both the encoder and decoder layers have a [[Feedforward neural network|feed-forward neural network]] for additional processing of the outputs and contain residual connections and layer normalization steps.
\\

\textbf{Scaled dot-product attention} \\
The transformer building blocks are scaled dot-product attention units. For each attention unit, the transformer model learns three weight matrices: the query weights \(W_Q\), the key weights \(W_K\), and the value weights \(W_V\). For each token \(i\), the input token representation \(x_i\) is multiplied with each of the three weight matrices to produce a query vector \(q_i = x_iW_Q\), a key vector \(k_i = x_iW_K\), and a value vector \(v_i=x_iW_V\). Attention weights are calculated using the query and key vectors: the attention weight \(a_{ij}\) from token  \(i\)to token \(j\)is the dot product between \(q_i\) and \(k_j\). The attention weights are divided by the square root of the dimension of the key vectors, \(\sqrt{d_k}\), which stabilizes gradients during training, and passed through a softmax which normalizes the weights.
\\

The fact that \(W_Q\) and \(W_K\)are different matrices allows attention to be non-symmetric: if token \(i\) attends to token  \(j\)(i.e.  \(q_i\cdot k_j\) is large), this does not necessarily mean that token  \(j\)will attend to token \(i\) (i.e. \(q_j\cdot k_i\) could be small). The output of the attention unit for token \(i\)is the weighted sum of the value vectors of all tokens, weighted by \(a_{ij}\), the attention from token \(i\) to each token.
\\

The attention calculation for all tokens can be expressed as one large matrix calculation using the softmax, which is useful for training due to computational matrix operation optimizations that quickly compute matrix operations. The matrices \(Q\), \(K\) and \(V\) are defined as the matrices where the \(i\)th rows are vectors \(q_i\), \(k_i\), and \(v_i\) respectively. Then we can represent the attention as
\begin{align}
\text{Attention}(Q, K, V) = \text{softmax}\left(\frac{QK^\mathrm{T}}{\sqrt{d_k}}\right)V
\end{align}

where softmax is taken over the horizontal axis.
\\

\textbf{Multi-head attention} \\
One set of \(\left( W_Q, W_K, W_V \right)\) matrices is called an ''attention head'', and each layer in a transformer model has multiple attention heads. While each attention head attends to the tokens that are relevant to each token, multiple attention heads allow the model to do this for different definitions of "relevance". In addition, the influence field representing relevance can become progressively dilated in successive layers. Many transformer attention heads encode relevance relations that are meaningful to humans. For example, some attention heads can attend mostly to the next word, while others mainly attend from verbs to their direct objects.
\\

The computations for each attention head can be performed in parallel, which allows for fast processing. The outputs for the attention layer are concatenated to pass into the feed-forward neural network layers.
\\

Concretely, let the multiple attention heads be indexed by \(i\), then we have
\begin{multline}
\text{MultiheadedAttention}(Q, K, V) \\ =  \text{Concat}_{i \in [\# heads]}(\text{Attention}(XW^Q_i, XW^K_i, XW^V_i)) W^O
\end{multline}
where the matrix \(X\) is the concatenation of word embeddings, and the matrices \(W^Q_i, W^K_i, W^V_i\) are "projection matrices" owned by individual attention head \(i\), and \(W^O\) is a final projection matrix owned by the whole multi-headed attention head.
\\

\textbf{Masked attention}\\
It may be necessary to cut out attention links between some word-pairs. For example, the decoder for token position \(t\) should not have access to token position \(t+1\). This may be accomplished before the softmax stage by adding a mask matrix  \(M\)that is \(-\infty\) at entries where the attention link must be cut, and \(0\) at other places:
\\

\textbf{Encoder}\\
Each encoder consists of two major components: a self-attention mechanism and a feed-forward neural network. The self-attention mechanism accepts input encodings from the previous encoder and weights their relevance to each other to generate output encodings. The feed-forward neural network further processes each output encoding individually. These output encodings are then passed to the next encoder as its input, as well as to the decoders.
\\

The first encoder takes positional information and embeddings of the input sequence as its input, rather than encodings. The positional information is necessary for the transformer to make use of the order of the sequence, because no other part of the transformer makes use of this.
\\

The encoder is bidirectional. Attention can be placed on tokens before and after the current token. Tokens are used instead of words to account for polysemy.
\\

\textbf{Positional encoding}\\
A positional encoding is a fixed-size vector representation that encapsulates the relative positions of tokens within a target sequence: it provides the transformer model with information about ''where'' the words are in the input sequence.

The positional encoding is defined as a function of type \(f: \mathbb{R} \to \mathbb{R}^d; d \in \mathbb{Z}, d > 0\), where \(d\)is a positive even integer. The full positional encoding – as defined in the original paper – is given by the equation:
\[(f(t)_{2k}, f(t)_{2k+1}) = (\sin(\theta), \cos(\theta)) \quad \forall k \in \{0, 1, \ldots, d/2 - 1\}\]
where \(\theta = \frac{t}{r^k}, r = N^{2/d}\).\\

Here, \(N\)is a free parameter that should be significantly larger than the biggest \(k\)that would be input into the positional encoding function. In the original paper, the authors chose \(N=10000\).

The function is in a simpler form when written as a complex function of type
\(f: \mathbb{R} \to \mathbb C^{d/2}\)

\[f(t) = \left(e^{it/r^k}\right)_{k=0, 1, \ldots, \frac d 2 - 1}\] 
where \(r = N^{2/d}\).

The main reason the authors chose this as the positional encoding function is that it allows one to perform shifts as linear transformations:
\[f(t + \Delta t) = \mathrm{diag}(f(\Delta t)) f(t)\]
where \(\Delta t \in R\) is the distance one wishes to shift. This allows the transformer to take any encoded position, and find the encoding of the position n-steps-ahead or n-steps-behind, by a matrix multiplication.
\\

By taking a linear sum, any convolution can also be implemented as linear transformations:

\[\sum_j c_j f(t + \Delta t_j) = \left(\sum_j c_j \,\mathrm{diag}(f(\Delta t_j))\right) f(t)\]

for any constants \(c_j\). This allows the transformer to take any encoded position and find a linear sum of the encoded locations of its neighbors. This sum of encoded positions, when fed into the attention mechanism, would create attention weights on its neighbors, much like what happens in a convolutional neural network language model. In the author's words, "we hypothesized it would allow the model to easily learn to attend by relative position".
\\

In typical implementations, all operations are done over the real numbers, not the complex numbers, but since complex multiplication can be implemented as real 2-by-2 matrix multiplication, this is a mere notational difference.
\\

\textbf{Decoder}\\
Each decoder consists of three major components: a self-attention mechanism, an attention mechanism over the encodings, and a feed-forward neural network. The decoder functions in a similar fashion to the encoder, but an additional attention mechanism is inserted which instead draws relevant information from the encodings generated by the encoders. This mechanism can also be called the ''encoder-decoder attention''.
\\

Like the first encoder, the first decoder takes positional information and embeddings of the output sequence as its input, rather than encodings. The transformer must not use the current or future output to predict an output, so the output sequence must be partially masked to prevent this reverse information flow. This allows for autoregressive text generation. For all attention heads, attention can't be placed on following tokens. The last decoder is followed by a final linear transformation and softmax layer, to produce the output probabilities over the vocabulary.
\\

All members of OpenAI's GPT series have a decoder-only architecture.
\\

\subsubsection{\textbf{Attention}}
\cite{Attention}
Machine learning-based attention is a mechanism mimicking cognitive attention. It calculates "soft" weights for each word, more precisely for its embedding, in the context window. It can do it either in parallel (such as in transformers) or sequentially (such as recurrent neural networks). "Soft" weights can change during each runtime, in contrast to "hard" weights, which are (pre-)trained and fine-tuned and remain frozen afterwards.
\\

Attention was developed to address the weaknesses of recurrent neural networks, where words in a sentence are slowly processed one at a time. Recurrent neural networks favor more recent words at the end of a sentence while earlier words fade away in volatile neural activations. Attention gives all words equal access to any part of a sentence in a faster parallel scheme and no longer suffers the wait time of serial processing. Earlier uses attached this mechanism to a serial recurrent neural network's language translation system (below), but later uses in Transformers large language models removed the recurrent neural network and relied heavily on the faster parallel attention scheme.
\\

\textbf{Core calculation}\\
The attention network was designed to identify the highest correlations amongst words within a sentence, assuming that it has learned those patterns from the training corpus.  This correlation is captured in neuronal weights through back-propagation from unsupervised pretraining.
\\

The example below shows how correlations are identified once a network has been trained and has the right weights.  When looking at the word "that" in the sentence "see that girl run", the network should be able to identify "girl" as a highly correlated word.  For simplicity this example focuses on the word "that", but in actuality all words receive this treatment in parallel and the resulting soft-weights and context vectors are stacked into matrices for further task- specific use.
\\

The query vector is compared (via dot product) with each word in the keys. This helps the model discover the most relevant word for the query word. In this case "girl" was determined to be the most relevant word for "that". The result (size 4 in this case) is run through the softmax function, producing a vector of size 4 with probabilities summing to 1. Multiplying this against the value matrix effectively amplifies the signal for the most important words in the sentence and diminishes the signal for less important words.
\\

The structure of the input data is captured in the \(Q_\textbf{w}\)and \(K_\textbf{w}\) weights, and the  \(V_\textbf{w}\) weights express that structure in terms of more meaningful features for the task being trained for.  For this reason, the attention head components are called Query ({{Q}}), Key ({{K}}), and Value ({{V}})—a loose and possibly misleading analogy with relational database systems.
\\

Note that the context vector for "that" does not rely on context vectors for the other words; therefore the context vectors of all words can be calculated using the whole matrix {{math|X}}, which includes all the word embeddings, instead of a single word's embedding vector \(\textbf{x}\) in the formula above, thus parallelizing the calculations. Now, the softmax can be interpreted as a matrix softmax acting on separate rows.  This is a huge advantage over recurrent networks which must operate sequentially.
\\

\subsubsection{\textbf{ViT}}
\cite{ViT}
 '''Vision Transformer''' ('''ViT''') is a transformer designed for computer vision. Transformers were introduced in 2017, The basic structure is to break down input images as a series of patches, then tokenized, before applying the tokens to a standard Transformer architecture.
\\

 The attention mechanism in a ViT repeatedly transforms representation vectors of image patches, incorporating more and more semantic relations between image patches in an image. This is analogous to how in natural language processing, as representation vectors flow through a Transformers, they incorporate more and more semantic relations between words, from syntax to semantics.
\\

 ViT has found applications in image recognition, image segmentation, and autonomous driving.
\\

 \textbf{Architecture}\\
 The basic architecture, used by the original 2020 paper, is as follows. In summary, it is a BERT-like encoder-only Transformer.
The input image is of type \(\mathbb{R}^{H\times W \times C}\), where \(H, W, C\) are height, width, channel RGB. It is then split into square-shaped patches of type \(\mathbb{R}^{P\times P \times C}\). 
\\

For each patch, the patch is pushed through a linear operator, to obtain a vector ("patch embedding"). The position of the patch is also transformed into a vector by "position encoding". The two vectors are added, then pushed through several Transformer encoders.
\\

\textbf{Classification} \\
The above architecture turns an image into a sequence of vector representations. To use the vector representation for downstream applications, one needs to add some network modules on top of it.
\\

For example, to use it for classification, one can add a shallow MLP on top of it that outputs a probability distribution over classes. The original paper uses a linear-GeLU-linear-softmax network.
\\

\textbf{Vision Transformer}\\
Transformers found their initial applications in natural language processing tasks, as demonstrated by language models such as BERT (language model) and GPT-3. By contrast the typical image processing system uses a convolutional neural network (CNN). Well-known projects include Xception, ResNet, EfficientNet, DenseNet, and Inception
\\

Transformers measure the relationships between pairs of input tokens (words in the case of text strings), termed attention. The cost is quadratic in the number of tokens. For images, the basic unit of analysis is the pixel. However, computing relationships for every pixel pair in a typical image is prohibitive in terms of memory and computation. Instead, ViT computes relationships among pixels in various small sections of the image (e.g., 16x16 pixels), at a drastically reduced cost. The sections (with positional embeddings) are placed in a sequence. The embeddings are learnable vectors. Each section is arranged into a linear sequence and multiplied by the embedding matrix. The result, with the position embedding is fed to the transformer.
\\

As in the case of BERT, a fundamental role in classification tasks is played by the class token. A special token that is used as the only input of the final MLP Head as it has been influenced by all the others.
\\

The architecture for image classification is the most common and uses only the Transformer Encoder in order to transform the various input tokens. However, there are also other applications in which the decoder part of the traditional Transformer Architecture is also used.
\\

In Masked Autoencoder, there are two ViTs put end-to-end. The first one takes in image patches with positional encoding, and outputs vectors representing each patch. The second one takes in vectors with positional encoding and outputs image patches again. During training, both ViTs are used. An image is cut into patches, and only 25\% of the patches are put into the first ViT. The second ViT takes the encoded vectors and outputs a reconstruction of the full image. During use, only the first ViT is used.
\\

\subsection{\textbf{OpenCV}}
\cite{opencv} OpenCV (Open Source Computer Vision Library) is an open source computer vision and machine learning software library.
\\

The library has more than 2500 optimized algorithms, which includes a comprehensive set of both classic and state-of-the-art computer vision and machine learning algorithms. These algorithms can be used to detect and recognize faces, identify objects, classify human actions in videos, track camera movements, track moving objects, extract 3D models of objects, produce 3D point clouds from stereo cameras, stitch images together to produce a high resolution image of an entire scene, find similar images from an image database, remove red eyes from images taken using flash, follow eye movements, recognize scenery and establish markers to overlay it with augmented reality, etc. OpenCV has more than 47 thousand people of user community and estimated number of downloads exceeding 18 million. The library is used extensively in companies, research groups and by governmental bodies.
\\

It has C++, Python, Java and MATLAB interfaces and supports Windows, Linux, Android and Mac OS. OpenCV leans mostly towards real-time vision applications and takes advantage of MMX and SSE instructions when available. A full-featured CUDAand OpenCL interfaces are being actively developed right now. There are over 500 algorithms and about 10 times as many functions that compose or support those algorithms. OpenCV is written natively in C++ and has a templated interface that works seamlessly with STL containers. Since our goal is to diagnose strokes through facial expressions, we have to utilize computer vision technology. We implemented functions like image-to-vector conversion using OpenCV, one of the most renowned libraries in computer vision.
\\

%우리는 얼굴 표정을 통한 뇌졸중 진단이 목적이기에 computer vision 기술을 활용해야한다. 이미지를 벡터로 변환하는 등의 function을 computer vision에서 가장 유명한 openCV를 통해 구현하였다.%

\subsection{\textbf{dlib}}
\cite{dlib} Dlib is a general purpose cross-platform software library written in the programming language C++. Its design is heavily influenced by ideas from design by contract and component-based software engineering. Thus it is, first and foremost, a set of independent software components. It is open-source software released under a Boost Software License.
\\

Since development began in 2002, Dlib has grown to include a wide variety of tools. As of 2016, it contains software components for dealing with networking, threads, graphical user interfaces, data structures, linear algebra, machine learning, image processing, data mining, XML and text parsing, numerical optimization, Bayesian networks, and many other tasks. In recent years, much of the development has been focused on creating a broad set of statistical machine learning tools and in 2009 Dlib was published in the Journal of Machine Learning Research. Since then it has been used in a wide range of domains. 
\\

Dlib is a modern C++ toolkit containing machine learning algorithms and tools for creating complex software in C++ to solve real world problems. It is used in both industry and academia in a wide range of domains including robotics, embedded devices, mobile phones, and large high performance computing environments. Dlib's open source licensing allows you to use it in any application, free of charge.
\\

Unlike a lot of open source projects, this one provides complete and precise documentation for every class and function. There are also debugging modes that check the documented preconditions for functions. When this is enabled it will catch the vast majority of bugs caused by calling functions incorrectly or using objects in an incorrect manner.
We used dlib for Face recognition and Face landmark detection. Dlib provides functions for these purposes, which helped us progress the project more efficiently.\\
%우리는 Face recognition과 Face landmark detection을 위해 dlib을 사용하였다. dlib은 이를 위한 함수들을 제공하기에 더 빠르게 프로젝트를 진행하는것에 도움이 된다.%

\subsection{\textbf{face\_utils}}
\cite{faceutil} this is an opensource wrapper library for the most common face detection models.
It also provides multiple face utilities such as face cropping.
Supported detection models. first, face\_recognition (hog and cnn), second, retina face model third, haar cascade face detection. We used the face\_utils library from imutils to resize images.\\
%우리는 이미지를 resize하기 위해 imutils에서 face_utils 라이브러리를 사용하였다.%

\subsection{\textbf{pip}}
\cite{pip} pip (also known by Python 3's alias pip3) is a package-management system written in Python and is used to install and manage software packages. The Python Software Foundation recommends using pip for installing Python applications and its dependencies during deployment.\\
Pip connects to an online repository of public packages, called the Python Package Index. Pip can be configured to connect to other package repositories (local or remote), provided that they comply to Python Enhancement Proposal 503. The fields of AI and computer vision have become highly active, particularly in the context of Python. One can easily and quickly install and use libraries for these purposes through pip.\\
%AI와 computer vision 분야는 파이썬을 기준으로 많이 활성화되었다. pip를 통해 이를 위한 library들을 빠르고 쉽게 설치하고 사용할 수 있다.%

\subsection{\textbf{ssh}}
\cite{ssh} The Secure Shell Protocol (SSH) is a cryptographic network protocol for operating network services securely over an unsecured network. Its most notable applications are remote login and command-line execution.\\

SSH applications are based on a client–server architecture, connecting an SSH client instance with an SSH server. SSH operates as a layered protocol suite comprising three principal hierarchical components: the transport layer provides server authentication, confidentiality, and integrity; the user authentication protocol validates the user to the server; and the connection protocol multiplexes the encrypted tunnel into multiple logical communication channels.
\\

SSH was designed on Unix-like operating systems, as a replacement for Telnet and for unsecured remote Unix shell protocols, such as the Berkeley Remote Shell (rsh) and the related rlogin and rexec protocols, which all use insecure, plaintext transmission of authentication tokens. \\

Subsequent development of the protocol suite proceeded in several developer groups, producing several variants of implementation. The protocol specification distinguishes two major versions, referred to as SSH-1 and SSH-2. The most commonly implemented software stack is OpenSSH, released in 1999 as open-source software by the OpenBSD developers. Implementations are distributed for all types of operating systems in common use, including embedded systems. 
\\

We utilized SSH for efficient coding on Raspberry Pi and to establish a connection between the local environment and AWS.\\
%우리는 Raspberry pi에서의 효율적인 코딩과 local과 aws를 연결하기 위해 ssh를 활용하였다.%

\subsection{\textbf{VSCode}}
\cite{vscode} Visual Studio Code, also commonly referred to as VS Code, is a source-code editor made by Microsoft with the Electron Framework, for Windows, Linux and macOS. Features include support for debugging, syntax highlighting, intelligent code completion, snippets, code refactoring, and embedded Git. Users can change the theme, keyboard shortcuts, preferences, and install extensions that add functionality.
\\

In the Stack Overflow 2023 Developer Survey, Visual Studio Code was ranked the most popular developer environment tool among 86,544 respondents, with 73.71\% reporting that they use it. It increased its use among those learning to code versus those developing as a profession.
\\

Visual Studio Code is a source-code editor that can be used with a variety of programming languages, including C, C\#, C++, Fortran, Go, Java, JavaScript, Node.js, Python, Rust, and Julia. It is based on the Electron framework, which is used to develop Node.js web applications that run on the Blink layout engine. Visual Studio Code employs the same editor component (codenamed "Monaco") used in Azure DevOps (formerly called Visual Studio Online and Visual Studio Team Services).
\\

Out of the box, Visual Studio Code includes basic support for most common programming languages. This basic support includes syntax highlighting, bracket matching, code folding, and configurable snippets. Visual Studio Code also ships with IntelliSense for JavaScript, TypeScript, JSON, CSS, and HTML, as well as debugging support for Node.js. Support for additional languages can be provided by freely available extensions on the VS Code Marketplace. 
\\

VSCode is currently the most popular code editor. It is not only clean but also supports various languages and extension packages. We used this editor to enhance efficiency when programming.\\
%vscode는 현재 가장 인기있는 편집기이다. 깔끔할 뿐 아니라 다양한 언어와 extension 패키지를 지원한다. 프로그래밍을 할 때의 효율을 높이기 위해 해당 editor를 사용하였다. %

\subsection{\textbf{aws-iot}}
\cite{awsiot}
%AWS IoT는 IoT 디바이스를 다른 디바이스에 연결하는 클라우드 서비스와 AWS 클라우드 서비스를 제공합니다. AWS IoT는 IoT 디바이스를 AWS IoT 기반 솔루션에 통합하는 데 도움이 되는 디바이스 소프트웨어를 제공합니다. 디바이스를 AWS IoT에 연결할 수 있는 경우 AWS IoT는 AWS가 제공하는 클라우드 서비스에 디바이스를 연결할 수 있습니다.AWS IoT를 사용하면 솔루션에 가장 적합한 최신 기술을 선택할 수 있습니다. 현장에서 IoT 디바이스를 관리하고 지원할 수 있도록 AWS IoT Core는 다음 프로토콜을 지원합니다. MQTT, MQTT over WSS, HTTPS, LoRaWANAWS IoT Core 메시지 브로커는 MQTT 및 MQTT over WSS 프로토콜을 사용하여 메시지를 게시하고 구독하는 디바이스와 클라이언트를 지원합니다. HTTPS 프로토콜을 사용하여 메시지를 게시하는 디바이스와 클라이언트도 지원합니다.AWS IoT Core for LoRaWAN을 사용하면 무선 LoRaWAN(저전력 장거리 광역 네트워크) 디바이스를 연결하고 관리할 수 있습니다. AWS IoT Core for LoRaWAN은 LoRaWAN 네트워크 서버(LNS)를 개발하고 운영할 필요를 대체합니다. Raspberry Pi에서 aws를 효과적으로 이용하기위해 aws에서 배포한 Iot전용 SDK를 설치하였다.%
AWS IoT provides cloud services for connecting IoT devices to other devices and AWS cloud services. It offers device software that aids in integrating IoT devices into AWS IoT-based solutions. When devices are connected to AWS IoT, they can be linked to cloud services provided by AWS. AWS IoT allows you to choose the latest technologies that best suit your solution.
\\

In the field of managing and supporting IoT devices, AWS IoT Core supports the following protocols: MQTT, MQTT over WSS (WebSockets), HTTPS, and LoRaWAN. AWS IoT Core's message broker supports devices and clients that use MQTT and MQTT over WSS protocols for publishing and subscribing to messages. It also supports devices and clients that use the HTTPS protocol for message publication.
\\

AWS IoT Core for LoRaWAN enables the connection and management of wireless LoRaWAN (Low-Power Wide-Area Network) devices. It eliminates the need to develop and operate a LoRaWAN Network Server (LNS). To effectively utilize AWS on Raspberry Pi, you have installed AWS's dedicated IoT SDK.\\

\subsection{\textbf{Wi-fi}}
\cite{wifi} Wi-Fi is a family of wireless network protocols based on the IEEE 802.11 family of standards, which are commonly used for local area networking of devices and Internet access, allowing nearby digital devices to exchange data by radio waves. 
\\

These are the most widely used computer networks, used globally in home and small office networks to link devices and to provide Internet access with wireless routers and wireless access points in public places such as coffee shops, hotels, libraries, and airports to provide visitors.
\\

Wi-Fi technology may be used to provide local network and Internet access to devices that are within Wi-Fi range of one or more routers that are connected to the Internet. The coverage of one or more interconnected access points can extend from an area as small as a few rooms to as large as many square kilometres. Coverage in the larger area may require a group of access points with overlapping coverage. For example, public outdoor Wi-Fi technology has been used successfully in wireless mesh networks in London. An international example is Fon.
\\

We use Raspberry Pi to implement true IoT technology. To connect Raspberry Pi to the internet, we have the option of either directly plugging in an Ethernet LAN cable or using Wi-Fi. Given that we designed the project with the consideration of it being integrated into home appliances, we chose to use Wi-Fi for wireless internet connectivity instead of a LAN cable.\\
%진정한 IoT 기술을 구현하기 위해 Raspberry pi를 사용한다. Rasberry pi에 인터넷을 연결해주기 위해서 LAN선을 직접 꽂거나 Wifi를 이용해야한다. 가전에 들어갈 것이라 생각하며 프로젝트를 진행하였기에 LAN선을 꼽는 것이 아닌 Wifi 무선 인터넷을 사용하였다.%

\subsection{\textbf{Github}}
\cite{github} GitHub is a platform and cloud-based service for software development and version control using Git, allowing developers to store and manage their code. 
\\

It provides the distributed version control of Git plus access control, bug tracking, software feature requests, task management, continuous integration, and wikis for every project. Headquartered in California, it has been a subsidiary of Microsoft since 2018.
\\

We use GitHub for efficient collaboration. We manage repositories and files remotely, create branches to manage different versions, and allow team members to easily see what new changes or additions they've made.\\
%%

\subsection{\textbf{NUGU}}

The NUGU AI speaker integration with the Raspberry Pi requires a NUGU developer account and access to the NUGU developer documentation. The integration begins with connecting to the NUGU API, an essential interface for communication between the Raspberry Pi and the NUGU AI speaker.
\\

As part of the integration prerequisites, developers must obtain the necessary API keys or credentials from the NUGU developer portal. These authentication mechanisms are critical for securing communication between the Raspberry Pi and the NUGU speaker, ensuring that only authorized requests are processed. The next phase involves implementing the interaction logic. A script running on the Raspberry Pi will enable triggering the NUGU speaker with predefined messages upon stroke detection by the machine learning model.
\\

Once the integration is complete, the NUGU AI speaker can be used to alert the user or call for help in the event of a stroke. The speaker can also be used to provide the user with information about stroke prevention and treatment.

\subsection{\textbf{Task distribution}}
\subsubsection{\textbf{Park Geonryul}}
% Google Colab, Pytorch를 이용해서 AI model을 구현하고 학습시켰다. AWS Lightsail을 이용해 가상머신을 구축하고 FastAPI를 사용해 AI model을 웹 서버에 배포하는 일을 맡아서 진행했다.
Park implemented an AI model and trained it using Google Colab and Pytorch. He was in charge of building a virtual machine using AWS Lightsail and deploying the AI model to a web server using FastAPI.\\

\subsubsection{\textbf{Lee Seungsu}}
Lee have planned this project and implemented focusing on overall IoT technology using Raspberry Pi. He developed algorithms for capturing faces using OpenCV and Dlib. Additionally, he created a two-level detection model for privacy. The process involves capturing images on the Raspberry Pi, detecting face changes in real-time, blurring the background, sending them to the server, and receiving the results to inform the customer.\\
\subsubsection{\textbf{Elia Ayoub}}
Elia did researches on the AI NUGU Speaker. He tried to find how to connect the speaker to the Rasberry Pi as well as how to deliver the condition found through the AI model to the users.\\
\subsubsection{\textbf{Ryan Jabbour}}
Ryan worked jointly with Elia on the AI NUGU Speaker and worked on keeping a logical progress of the project for the group while keeping everything in order such as documentation and team work and meetings.\\