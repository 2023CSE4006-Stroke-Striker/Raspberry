{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oaa4QmSLIOuV",
        "outputId": "f0634e6b-3bc4-405a-ed47-e12b28d5b79f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7c9bca0a36b0>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.optim import Adam\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets.mnist import MNIST\n",
        "\n",
        "np.random.seed(0)\n",
        "torch.manual_seed(0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "from torchvision.io import read_image"
      ],
      "metadata": {
        "id": "7wFOKyClJYIg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StrokeImageDataset(Dataset):\n",
        "    def __init__(self, annotations_file, img_dir, transform=None, target_transform=None):\n",
        "        self.img_labels = pd.read_csv(annotations_file, names=['file_name', 'label'])\n",
        "        self.img_dir = img_dir\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.img_labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
        "        image = read_image(img_path)\n",
        "        image = transforms.Resize((200, 200))(image)\n",
        "        image = transforms.Grayscale()(image)\n",
        "        label = self.img_labels.iloc[idx, 1]\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        if self.target_transform:\n",
        "            label = self.target_transform(label)\n",
        "        return image, label"
      ],
      "metadata": {
        "id": "BL2xVqVEJUCE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading data\n",
        "# transform = transforms.Compose([\n",
        "#     transforms.Resize((150, 150)),\n",
        "#     transforms.ToTensor(),\n",
        "# ])\n",
        "\n",
        "img_dir = \"/content/drive/MyDrive/main/datasets\"\n",
        "annotation_file = \"/content/drive/MyDrive/main/datasets/annotation_file.csv\"\n",
        "\n",
        "dataset = StrokeImageDataset(annotation_file, img_dir)\n",
        "dataset_size = len(dataset)\n",
        "\n",
        "train_size = int(dataset_size * 0.8)\n",
        "test_size = dataset_size - train_size\n",
        "\n",
        "    # random_split 사용\n",
        "train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
        "test_loader = DataLoader(test_dataset, shuffle=False, batch_size=16)\n",
        "\n",
        "\n",
        "    # 이미지와 정답(label)을 표시합니다.\n",
        "for index, (images, labels) in enumerate(train_loader):\n",
        "    print(f\"{index}/{len(train_loader)}\", end=' ')\n",
        "    print(\"x shape:\", images.shape, end=' ')\n",
        "    print(\"y shape:\", labels.shape)"
      ],
      "metadata": {
        "id": "gySskCBMBWDj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07a526dd-ef23-42ae-a56f-41ab39561bcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "1/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "2/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "3/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "4/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "5/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "6/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "7/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "8/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "9/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "10/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "11/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "12/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "13/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "14/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "15/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "16/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "17/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "18/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "19/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "20/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "21/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "22/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "23/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "24/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "25/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "26/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "27/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "28/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "29/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "30/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "31/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "32/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "33/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "34/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "35/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "36/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "37/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "38/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "39/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "40/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "41/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "42/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "43/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "44/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "45/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "46/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "47/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "48/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "49/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "50/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "51/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "52/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "53/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "54/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "55/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "56/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "57/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "58/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "59/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "60/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "61/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "62/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "63/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "64/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "65/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "66/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "67/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "68/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "69/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "70/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "71/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "72/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "73/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "74/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "75/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "76/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "77/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "78/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "79/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "80/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "81/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "82/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "83/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "84/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "85/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "86/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "87/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "88/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "89/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "90/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "91/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "92/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "93/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "94/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "95/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "96/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "97/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "98/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "99/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "100/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "101/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "102/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "103/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "104/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "105/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "106/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "107/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "108/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "109/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "110/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "111/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "112/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "113/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "114/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "115/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "116/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "117/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "118/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "119/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "120/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "121/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "122/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "123/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "124/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "125/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "126/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "127/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "128/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "129/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "130/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "131/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "132/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "133/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "134/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "135/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "136/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "137/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "138/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "139/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "140/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "141/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "142/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "143/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "144/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "145/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "146/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "147/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "148/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "149/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "150/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "151/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "152/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "153/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "154/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "155/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "156/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "157/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "158/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "159/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "160/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "161/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "162/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "163/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "164/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "165/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "166/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "167/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "168/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "169/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "170/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "171/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "172/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "173/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "174/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "175/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "176/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "177/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "178/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "179/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "180/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "181/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "182/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "183/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "184/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "185/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "186/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "187/189 x shape: torch.Size([16, 1, 200, 200]) y shape: torch.Size([16])\n",
            "188/189 x shape: torch.Size([8, 1, 200, 200]) y shape: torch.Size([8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Loading data\n",
        "\n",
        "    img_dir = \"/content/drive/MyDrive/main/datasets\"\n",
        "    annotation_file = \"/content/drive/MyDrive/main/datasets/annotation_file.csv\"\n",
        "\n",
        "    dataset = StrokeImageDataset(annotation_file, img_dir)\n",
        "    dataset_size = len(dataset)\n",
        "\n",
        "    train_size = int(dataset_size * 0.8)\n",
        "    test_size = dataset_size - train_size\n",
        "\n",
        "    # random_split 사용\n",
        "    train_dataset, test_dataset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    train_loader = DataLoader(train_dataset, shuffle=True, batch_size=16)\n",
        "    test_loader = DataLoader(test_dataset, shuffle=False, batch_size=16)\n",
        "\n",
        "    # Defining model and training options\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using device: \", device, f\"({torch.cuda.get_device_name(device)})\" if torch.cuda.is_available() else \"\")\n",
        "    model = MyViT((1, 200, 200), n_patches=100, n_blocks=2, hidden_d=3, n_heads=2, out_d=2).to(device)\n",
        "    N_EPOCHS = 5\n",
        "    LR = 0.005\n",
        "\n",
        "    # Training loop\n",
        "    optimizer = Adam(model.parameters(), lr=LR)\n",
        "    criterion = CrossEntropyLoss()\n",
        "    for epoch in trange(N_EPOCHS, desc=\"Training\"):\n",
        "        train_loss = 0.0\n",
        "        for batch in tqdm(train_loader, desc=f\"Epoch {epoch + 1} in training\", leave=False):\n",
        "            x, y = batch\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "\n",
        "            train_loss += loss.detach().cpu().item() / len(train_loader)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{N_EPOCHS} loss: {train_loss:.2f}\")\n",
        "\n",
        "    # Test loop\n",
        "    with torch.no_grad():\n",
        "        correct, total = 0, 0\n",
        "        test_loss = 0.0\n",
        "        for batch in tqdm(test_loader, desc=\"Testing\"):\n",
        "            x, y = batch\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            y_hat = model(x)\n",
        "            loss = criterion(y_hat, y)\n",
        "            test_loss += loss.detach().cpu().item() / len(test_loader)\n",
        "\n",
        "            correct += torch.sum(torch.argmax(y_hat, dim=1) == y).detach().cpu().item()\n",
        "            total += len(x)\n",
        "        print(f\"Test loss: {test_loss:.2f}\")\n",
        "        print(f\"Test accuracy: {correct / total * 100:.2f}%\")"
      ],
      "metadata": {
        "id": "PuTrPOtvIVUQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyViT(nn.Module):\n",
        "    def __init__(self, chw, n_patches=100, n_blocks=4, hidden_d=3, n_heads=4, out_d=2):\n",
        "        # Super constructor\n",
        "        super(MyViT, self).__init__()\n",
        "\n",
        "        # Attributes\n",
        "        self.chw = chw # ( C , H , W )\n",
        "        self.n_patches = n_patches\n",
        "        self.n_blocks = n_blocks\n",
        "        self.n_heads = n_heads\n",
        "        self.hidden_d = hidden_d\n",
        "\n",
        "        # Input and patches sizes\n",
        "        assert chw[1] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "        assert chw[2] % n_patches == 0, \"Input shape not entirely divisible by number of patches\"\n",
        "        self.patch_size = (chw[1] / n_patches, chw[2] / n_patches)\n",
        "\n",
        "        # 1) Linear mapper\n",
        "        self.input_d = int(chw[0] * self.patch_size[0] * self.patch_size[1])\n",
        "        self.linear_mapper = nn.Linear(self.input_d, self.hidden_d)\n",
        "\n",
        "        # 2) Learnable classification token\n",
        "        self.class_token = nn.Parameter(torch.rand(1, self.hidden_d))\n",
        "\n",
        "        # 3) Positional embedding\n",
        "        self.register_buffer('positional_embeddings', get_positional_embeddings(n_patches ** 2 + 1, hidden_d), persistent=False)\n",
        "\n",
        "        # 4) Transformer encoder blocks\n",
        "        self.blocks = nn.ModuleList([MyViTBlock(hidden_d, n_heads) for _ in range(n_blocks)])\n",
        "\n",
        "        # 5) Classification MLPk\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(self.hidden_d, out_d),\n",
        "            nn.Softmax(dim=-1)\n",
        "        )\n",
        "\n",
        "    def forward(self, images):\n",
        "        # Dividing images into patches\n",
        "        n, c, h, w = images.shape\n",
        "        patches = patchify(images, self.n_patches).to(self.positional_embeddings.device)\n",
        "\n",
        "        # Running linear layer tokenization\n",
        "        # Map the vector corresponding to each patch to the hidden size dimension\n",
        "        tokens = self.linear_mapper(patches)\n",
        "\n",
        "        # Adding classification token to the tokens\n",
        "        tokens = torch.cat((self.class_token.expand(n, 1, -1), tokens), dim=1)\n",
        "\n",
        "        # Adding positional embedding\n",
        "        out = tokens + self.positional_embeddings.repeat(n, 1, 1)\n",
        "\n",
        "        # Transformer Blocks\n",
        "        for block in self.blocks:\n",
        "            out = block(out)\n",
        "\n",
        "        # Getting the classification token only\n",
        "        out = out[:, 0]\n",
        "\n",
        "        return self.mlp(out) # Map to output dimension, output category distribution"
      ],
      "metadata": {
        "id": "Ok2dFEq_-a38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def patchify(images, n_patches):\n",
        "    n, c, h, w = images.shape\n",
        "\n",
        "    assert h == w, \"Patchify method is implemented for square images only\"\n",
        "\n",
        "    patches = torch.zeros(n, n_patches ** 2, h * w * c // n_patches ** 2)\n",
        "    patch_size = h // n_patches\n",
        "\n",
        "    for idx, image in enumerate(images):\n",
        "        for i in range(n_patches):\n",
        "            for j in range(n_patches):\n",
        "                patch = image[:, i * patch_size: (i + 1) * patch_size, j * patch_size: (j + 1) * patch_size]\n",
        "                patches[idx, i * n_patches + j] = patch.flatten()\n",
        "    return patches"
      ],
      "metadata": {
        "id": "glKeiRgG_vZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_positional_embeddings(sequence_length, d):\n",
        "    result = torch.ones(sequence_length, d)\n",
        "    for i in range(sequence_length):\n",
        "        for j in range(d):\n",
        "            result[i][j] = np.sin(i / (10000 ** (j / d))) if j % 2 == 0 else np.cos(i / (10000 ** ((j - 1) / d)))\n",
        "    return result"
      ],
      "metadata": {
        "id": "C4kGFOUGhYK1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyMSA(nn.Module):\n",
        "    def __init__(self, d, n_heads=4):\n",
        "        super(MyMSA, self).__init__()\n",
        "        self.d = d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        assert d % n_heads == 0, f\"Can't divide dimension {d} into {n_heads} heads\"\n",
        "\n",
        "        d_head = int(d / n_heads)\n",
        "        self.q_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.k_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.v_mappings = nn.ModuleList([nn.Linear(d_head, d_head) for _ in range(self.n_heads)])\n",
        "        self.d_head = d_head\n",
        "        self.softmax = nn.Softmax(dim=-1)\n",
        "\n",
        "    def forward(self, sequences):\n",
        "        # Sequences has shape (N, seq_length, token_dim)\n",
        "        # We go into shape    (N, seq_length, n_heads, token_dim / n_heads)\n",
        "        # And come back to    (N, seq_length, item_dim)  (through concatenation)\n",
        "        result = []\n",
        "        for sequence in sequences:\n",
        "            seq_result = []\n",
        "            for head in range(self.n_heads):\n",
        "                q_mapping = self.q_mappings[head]\n",
        "                k_mapping = self.k_mappings[head]\n",
        "                v_mapping = self.v_mappings[head]\n",
        "\n",
        "                seq = sequence[:, head * self.d_head: (head + 1) * self.d_head]\n",
        "                q, k, v = q_mapping(seq), k_mapping(seq), v_mapping(seq)\n",
        "\n",
        "                attention = self.softmax(q @ k.T / (self.d_head ** 0.5))\n",
        "                seq_result.append(attention @ v)\n",
        "            result.append(torch.hstack(seq_result))\n",
        "        return torch.cat([torch.unsqueeze(r, dim=0) for r in result])"
      ],
      "metadata": {
        "id": "qhJCJBIChils"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyViTBlock(nn.Module):\n",
        "    def __init__(self, hidden_d, n_heads, mlp_ratio=4):\n",
        "        super(MyViTBlock, self).__init__()\n",
        "        self.hidden_d = hidden_d\n",
        "        self.n_heads = n_heads\n",
        "\n",
        "        self.norm1 = nn.LayerNorm(hidden_d)\n",
        "        self.mhsa = MyMSA(hidden_d, n_heads)\n",
        "        self.norm2 = nn.LayerNorm(hidden_d)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(hidden_d, mlp_ratio * hidden_d),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(mlp_ratio * hidden_d, hidden_d)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = x + self.mhsa(self.norm1(x))\n",
        "        out = out + self.mlp(self.norm2(out))\n",
        "        return out"
      ],
      "metadata": {
        "id": "9r132aw9hs9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "holIfnQ4jbQI",
        "outputId": "431300ce-d13e-4f91-b951-64e40e4403a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device:  cuda (Tesla V100-SXM2-16GB)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/5 [00:00<?, ?it/s]\n",
            "Epoch 1 in training:   0%|          | 0/189 [00:00<?, ?it/s]\u001b[A/usr/local/lib/python3.10/dist-packages/torchvision/transforms/functional.py:1603: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).\n",
            "  warnings.warn(\n",
            "\n",
            "Epoch 1 in training:   1%|          | 1/189 [00:02<06:34,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:   1%|          | 2/189 [00:04<06:35,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:   2%|▏         | 3/189 [00:06<07:02,  2.27s/it]\u001b[A\n",
            "Epoch 1 in training:   2%|▏         | 4/189 [00:08<06:59,  2.27s/it]\u001b[A\n",
            "Epoch 1 in training:   3%|▎         | 5/189 [00:11<06:56,  2.27s/it]\u001b[A\n",
            "Epoch 1 in training:   3%|▎         | 6/189 [00:13<06:43,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:   4%|▎         | 7/189 [00:15<06:31,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:   4%|▍         | 8/189 [00:17<06:25,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:   5%|▍         | 9/189 [00:19<06:22,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:   5%|▌         | 10/189 [00:21<06:23,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:   6%|▌         | 11/189 [00:23<06:17,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:   6%|▋         | 12/189 [00:25<06:10,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:   7%|▋         | 13/189 [00:27<06:08,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:   7%|▋         | 14/189 [00:29<06:05,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:   8%|▊         | 15/189 [00:32<06:04,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:   8%|▊         | 16/189 [00:34<06:02,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:   9%|▉         | 17/189 [00:36<05:56,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  10%|▉         | 18/189 [00:38<05:57,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  10%|█         | 19/189 [00:40<05:54,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  11%|█         | 20/189 [00:42<05:55,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  11%|█         | 21/189 [00:44<06:00,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  12%|█▏        | 22/189 [00:46<05:58,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  12%|█▏        | 23/189 [00:49<05:57,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  13%|█▎        | 24/189 [00:51<05:54,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  13%|█▎        | 25/189 [00:53<05:50,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  14%|█▍        | 26/189 [00:55<05:49,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  14%|█▍        | 27/189 [00:57<05:42,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  15%|█▍        | 28/189 [00:59<05:48,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  15%|█▌        | 29/189 [01:02<05:50,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  16%|█▌        | 30/189 [01:04<05:44,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  16%|█▋        | 31/189 [01:06<05:48,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  17%|█▋        | 32/189 [01:08<05:40,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  17%|█▋        | 33/189 [01:10<05:39,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  18%|█▊        | 34/189 [01:12<05:32,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  19%|█▊        | 35/189 [01:15<05:30,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  19%|█▉        | 36/189 [01:17<05:31,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  20%|█▉        | 37/189 [01:19<05:25,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  20%|██        | 38/189 [01:21<05:23,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  21%|██        | 39/189 [01:23<05:22,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  21%|██        | 40/189 [01:25<05:17,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  22%|██▏       | 41/189 [01:27<05:13,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  22%|██▏       | 42/189 [01:29<05:08,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  23%|██▎       | 43/189 [01:31<05:04,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  23%|██▎       | 44/189 [01:33<05:00,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  24%|██▍       | 45/189 [01:35<04:57,  2.06s/it]\u001b[A\n",
            "Epoch 1 in training:  24%|██▍       | 46/189 [01:38<04:58,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  25%|██▍       | 47/189 [01:40<04:52,  2.06s/it]\u001b[A\n",
            "Epoch 1 in training:  25%|██▌       | 48/189 [01:42<04:49,  2.06s/it]\u001b[A\n",
            "Epoch 1 in training:  26%|██▌       | 49/189 [01:44<04:51,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  26%|██▋       | 50/189 [01:46<04:53,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  27%|██▋       | 51/189 [01:48<05:02,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  28%|██▊       | 52/189 [01:51<05:01,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  28%|██▊       | 53/189 [01:53<04:52,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  29%|██▊       | 54/189 [01:55<04:56,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  29%|██▉       | 55/189 [01:57<04:55,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  30%|██▉       | 56/189 [01:59<04:50,  2.18s/it]\u001b[A\n",
            "Epoch 1 in training:  30%|███       | 57/189 [02:01<04:45,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  31%|███       | 58/189 [02:04<04:41,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  31%|███       | 59/189 [02:06<04:36,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  32%|███▏      | 60/189 [02:08<04:31,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  32%|███▏      | 61/189 [02:10<04:26,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  33%|███▎      | 62/189 [02:12<04:28,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  33%|███▎      | 63/189 [02:14<04:30,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  34%|███▍      | 64/189 [02:16<04:28,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  34%|███▍      | 65/189 [02:18<04:24,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  35%|███▍      | 66/189 [02:20<04:22,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  35%|███▌      | 67/189 [02:23<04:20,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  36%|███▌      | 68/189 [02:25<04:24,  2.18s/it]\u001b[A\n",
            "Epoch 1 in training:  37%|███▋      | 69/189 [02:27<04:18,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  37%|███▋      | 70/189 [02:29<04:12,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  38%|███▊      | 71/189 [02:31<04:09,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  38%|███▊      | 72/189 [02:33<04:07,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  39%|███▊      | 73/189 [02:35<04:04,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  39%|███▉      | 74/189 [02:37<04:03,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  40%|███▉      | 75/189 [02:40<03:59,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  40%|████      | 76/189 [02:42<03:55,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  41%|████      | 77/189 [02:44<03:54,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  41%|████▏     | 78/189 [02:46<04:04,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  42%|████▏     | 79/189 [02:48<04:05,  2.23s/it]\u001b[A\n",
            "Epoch 1 in training:  42%|████▏     | 80/189 [02:52<04:44,  2.61s/it]\u001b[A\n",
            "Epoch 1 in training:  43%|████▎     | 81/189 [02:54<04:27,  2.48s/it]\u001b[A\n",
            "Epoch 1 in training:  43%|████▎     | 82/189 [02:56<04:11,  2.35s/it]\u001b[A\n",
            "Epoch 1 in training:  44%|████▍     | 83/189 [02:58<04:02,  2.29s/it]\u001b[A\n",
            "Epoch 1 in training:  44%|████▍     | 84/189 [03:00<03:54,  2.23s/it]\u001b[A\n",
            "Epoch 1 in training:  45%|████▍     | 85/189 [03:03<03:47,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  46%|████▌     | 86/189 [03:05<03:43,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  46%|████▌     | 87/189 [03:07<03:39,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  47%|████▋     | 88/189 [03:09<03:35,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  47%|████▋     | 89/189 [03:11<03:32,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  48%|████▊     | 90/189 [03:13<03:29,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  48%|████▊     | 91/189 [03:15<03:30,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  49%|████▊     | 92/189 [03:17<03:24,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  49%|████▉     | 93/189 [03:19<03:21,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  50%|████▉     | 94/189 [03:21<03:18,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  50%|█████     | 95/189 [03:24<03:17,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  51%|█████     | 96/189 [03:26<03:13,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  51%|█████▏    | 97/189 [03:28<03:12,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  52%|█████▏    | 98/189 [03:30<03:10,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  52%|█████▏    | 99/189 [03:32<03:06,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  53%|█████▎    | 100/189 [03:34<03:05,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  53%|█████▎    | 101/189 [03:36<03:06,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  54%|█████▍    | 102/189 [03:38<03:10,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  54%|█████▍    | 103/189 [03:41<03:07,  2.18s/it]\u001b[A\n",
            "Epoch 1 in training:  55%|█████▌    | 104/189 [03:43<03:02,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  56%|█████▌    | 105/189 [03:45<03:06,  2.22s/it]\u001b[A\n",
            "Epoch 1 in training:  56%|█████▌    | 106/189 [03:47<03:07,  2.26s/it]\u001b[A\n",
            "Epoch 1 in training:  57%|█████▋    | 107/189 [03:50<03:04,  2.25s/it]\u001b[A\n",
            "Epoch 1 in training:  57%|█████▋    | 108/189 [03:52<02:59,  2.21s/it]\u001b[A\n",
            "Epoch 1 in training:  58%|█████▊    | 109/189 [03:54<02:52,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  58%|█████▊    | 110/189 [03:56<02:51,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  59%|█████▊    | 111/189 [03:58<02:47,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  59%|█████▉    | 112/189 [04:00<02:44,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  60%|█████▉    | 113/189 [04:02<02:42,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  60%|██████    | 114/189 [04:04<02:38,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  61%|██████    | 115/189 [04:07<02:36,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  61%|██████▏   | 116/189 [04:09<02:33,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  62%|██████▏   | 117/189 [04:11<02:37,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  62%|██████▏   | 118/189 [04:13<02:35,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  63%|██████▎   | 119/189 [04:15<02:32,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  63%|██████▎   | 120/189 [04:17<02:27,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  64%|██████▍   | 121/189 [04:19<02:23,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  65%|██████▍   | 122/189 [04:22<02:21,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  65%|██████▌   | 123/189 [04:24<02:18,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  66%|██████▌   | 124/189 [04:26<02:15,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  66%|██████▌   | 125/189 [04:28<02:12,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  67%|██████▋   | 126/189 [04:30<02:13,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  67%|██████▋   | 127/189 [04:32<02:10,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  68%|██████▊   | 128/189 [04:34<02:08,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  68%|██████▊   | 129/189 [04:36<02:05,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  69%|██████▉   | 130/189 [04:38<02:02,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  69%|██████▉   | 131/189 [04:40<02:01,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  70%|██████▉   | 132/189 [04:43<02:03,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  70%|███████   | 133/189 [04:45<02:00,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  71%|███████   | 134/189 [04:47<01:59,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  71%|███████▏  | 135/189 [04:49<01:58,  2.19s/it]\u001b[A\n",
            "Epoch 1 in training:  72%|███████▏  | 136/189 [04:53<02:15,  2.56s/it]\u001b[A\n",
            "Epoch 1 in training:  72%|███████▏  | 137/189 [04:55<02:06,  2.43s/it]\u001b[A\n",
            "Epoch 1 in training:  73%|███████▎  | 138/189 [04:57<02:01,  2.39s/it]\u001b[A\n",
            "Epoch 1 in training:  74%|███████▎  | 139/189 [04:59<01:57,  2.35s/it]\u001b[A\n",
            "Epoch 1 in training:  74%|███████▍  | 140/189 [05:02<01:52,  2.31s/it]\u001b[A\n",
            "Epoch 1 in training:  75%|███████▍  | 141/189 [05:04<01:48,  2.26s/it]\u001b[A\n",
            "Epoch 1 in training:  75%|███████▌  | 142/189 [05:06<01:43,  2.21s/it]\u001b[A\n",
            "Epoch 1 in training:  76%|███████▌  | 143/189 [05:08<01:40,  2.18s/it]\u001b[A\n",
            "Epoch 1 in training:  76%|███████▌  | 144/189 [05:10<01:36,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  77%|███████▋  | 145/189 [05:12<01:32,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  77%|███████▋  | 146/189 [05:14<01:29,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  78%|███████▊  | 147/189 [05:16<01:27,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  78%|███████▊  | 148/189 [05:18<01:24,  2.07s/it]\u001b[A\n",
            "Epoch 1 in training:  79%|███████▉  | 149/189 [05:20<01:23,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  79%|███████▉  | 150/189 [05:22<01:20,  2.06s/it]\u001b[A\n",
            "Epoch 1 in training:  80%|███████▉  | 151/189 [05:24<01:19,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  80%|████████  | 152/189 [05:26<01:17,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  81%|████████  | 153/189 [05:29<01:15,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  81%|████████▏ | 154/189 [05:31<01:13,  2.09s/it]\u001b[A\n",
            "Epoch 1 in training:  82%|████████▏ | 155/189 [05:33<01:12,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  83%|████████▎ | 156/189 [05:35<01:09,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  83%|████████▎ | 157/189 [05:37<01:06,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  84%|████████▎ | 158/189 [05:39<01:04,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  84%|████████▍ | 159/189 [05:41<01:02,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  85%|████████▍ | 160/189 [05:43<01:01,  2.13s/it]\u001b[A\n",
            "Epoch 1 in training:  85%|████████▌ | 161/189 [05:46<01:01,  2.21s/it]\u001b[A\n",
            "Epoch 1 in training:  86%|████████▌ | 162/189 [05:48<00:58,  2.18s/it]\u001b[A\n",
            "Epoch 1 in training:  86%|████████▌ | 163/189 [05:50<00:57,  2.21s/it]\u001b[A\n",
            "Epoch 1 in training:  87%|████████▋ | 164/189 [05:52<00:55,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  87%|████████▋ | 165/189 [05:54<00:52,  2.17s/it]\u001b[A\n",
            "Epoch 1 in training:  88%|████████▊ | 166/189 [05:57<00:49,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  88%|████████▊ | 167/189 [05:59<00:47,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  89%|████████▉ | 168/189 [06:01<00:44,  2.14s/it]\u001b[A\n",
            "Epoch 1 in training:  89%|████████▉ | 169/189 [06:03<00:43,  2.16s/it]\u001b[A\n",
            "Epoch 1 in training:  90%|████████▉ | 170/189 [06:05<00:40,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  90%|█████████ | 171/189 [06:07<00:37,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  91%|█████████ | 172/189 [06:09<00:35,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  92%|█████████▏| 173/189 [06:12<00:35,  2.20s/it]\u001b[A\n",
            "Epoch 1 in training:  92%|█████████▏| 174/189 [06:14<00:32,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  93%|█████████▎| 175/189 [06:16<00:29,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  93%|█████████▎| 176/189 [06:18<00:27,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  94%|█████████▎| 177/189 [06:20<00:25,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  94%|█████████▍| 178/189 [06:22<00:23,  2.11s/it]\u001b[A\n",
            "Epoch 1 in training:  95%|█████████▍| 179/189 [06:24<00:21,  2.15s/it]\u001b[A\n",
            "Epoch 1 in training:  95%|█████████▌| 180/189 [06:26<00:19,  2.12s/it]\u001b[A\n",
            "Epoch 1 in training:  96%|█████████▌| 181/189 [06:28<00:16,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  96%|█████████▋| 182/189 [06:30<00:14,  2.08s/it]\u001b[A\n",
            "Epoch 1 in training:  97%|█████████▋| 183/189 [06:32<00:12,  2.10s/it]\u001b[A\n",
            "Epoch 1 in training:  97%|█████████▋| 184/189 [06:35<00:10,  2.09s/it]\u001b[A\n",
            "Training:   0%|          | 0/5 [06:35<?, ?it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-61-263240bbee7e>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-59-7b33236da5df>\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN_EPOCHS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf\"Epoch {epoch + 1} in training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1181\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1182\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1183\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1184\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    362\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-44-85fe225f63ff>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mResize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimg_labels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_image\u001b[0;34m(path, mode)\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecode_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torchvision/io/image.py\u001b[0m in \u001b[0;36mread_file\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_scripting\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tracing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_ops.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;31m# We save the function ptr as the `op` attribute on\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m         \u001b[0;31m# OpOverloadPacket to access it here.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 692\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    693\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m     \u001b[0;31m# TODO: use this to make a __dir__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/main/datasets/aug_1_8549.jpg'"
          ]
        }
      ]
    }
  ]
}